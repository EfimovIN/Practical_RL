{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AQpuhSkBTKjE"
   },
   "source": [
    "## Аппроксимация Q-функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3KgKLUiJTKjI"
   },
   "source": [
    "В этой тетрадке мы будем использовать библиотеку tensorflow для обучения нейронной сети, хотя можно использовать и любую другую библиотеку. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SDsUrk4tTKjK"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7IMFc1dTTKjP"
   },
   "source": [
    "Будем тестировать наши модели на классической задаче с перевернутым маятником:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-8pb2lfxTKjR",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11c761278>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\").env\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape\n",
    "\n",
    "plt.imshow(env.render(\"rgb_array\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vX54sySbTKjV"
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bk3-9NN5TKjZ"
   },
   "source": [
    "# Глубокое Q-обучение: построение сети\n",
    "\n",
    "Так как описание состояния в задаче с маятником представляет собой не \"сырые\" признаки, а уже предобработанные (координаты, углы), нам не нужна для начала сложная архитектура, начнем с такой:\n",
    "\n",
    "<img src=\"qlearningscheme.png\" caption=\"Архитектура сети\">\n",
    "Для начала попробуйте использовать только полносвязные слои (__L.Dense__) и линейные активационные функции. Сигмоиды и другие функции не будут работать с ненормализованными входными данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KHi0meFMTKja",
    "outputId": "3d9db427-b07f-4b40-a9ee-9b643410def4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.layers as L\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M6ZJDOPJTKjd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "network = keras.models.Sequential()\n",
    "network.add(L.InputLayer(state_dim))\n",
    "# строим сеть!\n",
    "#~~~~~~~~~~ Решение ~~~~~~~~~~~~~~~\n",
    "\n",
    " \n",
    "network.add(L.Dense(300, activation=\"relu\"))\n",
    "network.add(L.Dense(n_actions))\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kkOAJbTHTKji"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def get_action(state, epsilon=0):\n",
    "    \"\"\"\n",
    "    сэмплируем (eps greedy) действие  \n",
    "    \"\"\"\n",
    "    q_values = network.predict(state[None])[0]\n",
    "    \n",
    "    ### Ваш код здесь - нужно выбрать действия eps-жадно\n",
    "    # action = \n",
    "    #~~~~~~~~~~ Решение ~~~~~~~~~~~~~~~\n",
    "    \n",
    "     \n",
    "    if epsilon < random.random():\n",
    "        action = np.argmax(q_values)\n",
    "    else:\n",
    "        action = random.choice(range(n_actions))\n",
    "    \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    \n",
    "    return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "zsTrcYTSTKjk",
    "outputId": "86e4215c-366f-48fd-ee6f-e094053aa4b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e=0.0 tests passed\n",
      "e=0.1 tests passed\n",
      "e=0.5 tests passed\n",
      "e=1.0 tests passed\n"
     ]
    }
   ],
   "source": [
    "assert network.output_shape == (None, n_actions), \\\n",
    "    \"убедитесь, что стратегия переводит \\\n",
    "    s -> [Q(s,a0), ..., Q(s, a_last)]\"\n",
    "assert network.layers[-1].activation == \\\n",
    "       keras.activations.linear, \\\n",
    "    \"убедитесь, что вы предсказываете q без нелинейности\"\n",
    "# проверяем исследование\n",
    "s = env.reset()\n",
    "assert np.shape(get_action(s)) == (), \\\n",
    "    \"убедитесь, что возвращаете одно действие\"\n",
    "for eps in [0., 0.1, 0.5, 1.0]:\n",
    "    na = n_actions\n",
    "    st = np.bincount([get_action(s, epsilon=eps) \\\n",
    "                      for i in range(10000)],\n",
    "                     minlength=na)\n",
    "    ba = st.argmax()\n",
    "    assert abs(\n",
    "        st[ba] - 10000 * (1 - eps + eps / na)) < 200\n",
    "    for oa in range(na):\n",
    "        if oa != ba:\n",
    "            assert abs(st[oa] - 10000 * (eps / na)) < 200\n",
    "    print('e=%.1f tests passed' % eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YyKpjfO7TKjq"
   },
   "source": [
    "### Q-обучение через градиентный спуск\n",
    "\n",
    "Теперь будем приближать Q-функцию агента, минимизируя TD функцию потерь:\n",
    "$$ L = { 1 \\over N} \\sum_i (Q_{\\theta}(s,a) - [r(s,a) + \\gamma \\cdot max_{a'} Q_{-}(s', a')]) ^2. $$\n",
    "\n",
    "Основная тонкость состоит в использовании  $Q_{-}(s',a')$. Эта та же самая функция, что и $Q_{\\theta}$, которая является выходом нейронной сети, но при обучении сети, мы не пропускаем через эти слои градиенты. Для этого используется функция `tf.stop_gradient`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KOw0pH5WTKjs"
   },
   "outputs": [],
   "source": [
    "# Создаем placeholders для <s, a, r, s'>, \n",
    "# а также индикатор окончания эпизода (is_done = True)\n",
    "states_ph = tf.placeholder('float32', \n",
    "                           shape=(None,) + state_dim)\n",
    "actions_ph = tf.placeholder('int32', shape=[None])\n",
    "rewards_ph = tf.placeholder('float32', shape=[None])\n",
    "next_states_ph = tf.placeholder('float32', \n",
    "                           shape=(None,) + state_dim)\n",
    "is_done_ph = tf.placeholder('bool', shape=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L6MRQ2z6TKjx"
   },
   "outputs": [],
   "source": [
    "# получаем q для всех действий, в текущем состоянии\n",
    "predicted_qvalues = network(states_ph)\n",
    "\n",
    "# получаем q-values для выбранного действия\n",
    "predicted_qvalues_for_actions =\\\n",
    "tf.reduce_sum(\n",
    "predicted_qvalues * tf.one_hot(actions_ph, n_actions),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T0Sb5q9uTKjz"
   },
   "outputs": [],
   "source": [
    "gamma = 0.99\n",
    "\n",
    "# применяем сеть для получения q-value для next_states_ph\n",
    "# predicted_next_qvalues =\n",
    "#~~~~~~~~~~ Решение ~~~~~~~~~~~~~~~\n",
    "\n",
    " \n",
    "predicted_next_qvalues = network(next_states_ph)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# вычисляем V*(next_states) \n",
    "# по предсказанным следующим q-values\n",
    "# next_state_values =\n",
    "#~~~~~~~~~~ Решение ~~~~~~~~~~~~~~~\n",
    "\n",
    " \n",
    "next_state_values = tf.reduce_max(predicted_next_qvalues, axis=1)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# Вычисляем target q-values для функции потерь \n",
    "# target_qvalues_for_actions = \n",
    "#~~~~~~~~~~ Решение ~~~~~~~~~~~~~~~\n",
    "\n",
    " \n",
    "target_qvalues_for_actions = rewards_ph + gamma * next_state_values\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# для последнего действия используем \n",
    "# упрощенную формулу Q(s,a) = r(s,a) \n",
    "target_qvalues_for_actions =\\\n",
    "tf.where(is_done_ph, rewards_ph, \n",
    "         target_qvalues_for_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aA15Fi_8d4hL"
   },
   "source": [
    "$$ L = { 1 \\over N} \\sum_i (Q_{\\theta}(s,a) - [r(s,a) + \\gamma \\cdot max_{a'} Q_{-}(s', a')]) ^2. $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LK9euKgoTKj2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "### среднеквадратичная функция потерь stop_gradient\n",
    "# loss = \n",
    "#~~~~~~~~~~ Решение ~~~~~~~~~~~~~~~\n",
    "\n",
    " \n",
    "loss = (predicted_qvalues_for_actions - tf.stop_gradient(target_qvalues_for_actions))**2\n",
    "loss = tf.reduce_mean(loss)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# применяем AdamOptimizer\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5oZQ957tTKj5"
   },
   "outputs": [],
   "source": [
    "assert tf.gradients(loss, \\\n",
    "    [predicted_qvalues_for_actions])[0] is not None, \\\n",
    "\"убедитесь, что обновление выполняется\\\n",
    "только для выбранного действия\"\n",
    "assert tf.gradients(loss, \\\n",
    "    [predicted_next_qvalues])[0] is None, \\\n",
    "\"убедитесь, что вы не распространяете градиент Q_(s',a')\"\n",
    "assert predicted_next_qvalues.shape.ndims == 2, \\\n",
    "\"убедитесь, что вы предсказываете q для всех действий,\\\n",
    "следующего состояния\"\n",
    "assert next_state_values.shape.ndims == 1, \\\n",
    "\"убедитесь, что вы вычислили V(s') как максимум\\\n",
    "только по оси действий, а не по всем осям\"\n",
    "assert target_qvalues_for_actions.shape.ndims == 1, \\\n",
    "\"что-то не так с целевыми q-значениями,\\\n",
    "они должны быть вектором\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "adITE6BaTKj-"
   },
   "source": [
    "### Playing the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YWIDEK7ATKkA"
   },
   "outputs": [],
   "source": [
    "def generate_session(t_max=1000, epsilon=0, train=False):\n",
    "    \"\"\"генерация сессии\"\"\"\n",
    "    total_reward = 0\n",
    "    s = env.reset()\n",
    "    \n",
    "    for t in range(t_max):\n",
    "        a = get_action(s, epsilon=epsilon)       \n",
    "        next_s, r, done, _ = env.step(a)\n",
    "        \n",
    "        if train:\n",
    "            sess.run(train_step,{\n",
    "                states_ph: [s], actions_ph: [a], \n",
    "                rewards_ph: [r], next_states_ph: [next_s], \n",
    "                is_done_ph: [done]\n",
    "            })\n",
    "\n",
    "        total_reward += r\n",
    "        s = next_s\n",
    "        if done: break\n",
    "            \n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TCeeMefwTKkC"
   },
   "outputs": [],
   "source": [
    "epsilon = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "-fMjfHxiTKkE",
    "outputId": "cc8bb4c7-37ff-49f8-bb38-ed132adbc730",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Error while reading resource variable beta1_power from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/beta1_power/N10tensorflow3VarE does not exist.\n\t [[node Adam/update_dense_1/kernel/ResourceApplyAdam/ReadVariableOp (defined at <ipython-input-15-e61309f3b57c>:12) ]]\n\nCaused by op 'Adam/update_dense_1/kernel/ResourceApplyAdam/ReadVariableOp', defined at:\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/asyncio/base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/asyncio/base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-e61309f3b57c>\", line 12, in <module>\n    train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 413, in minimize\n    name=name)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 612, in apply_gradients\n    update_ops.append(processor.update_op(self, grad))\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 171, in update_op\n    update_op = optimizer._resource_apply_dense(g, self._v)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/training/adam.py\", line 175, in _resource_apply_dense\n    grad, use_locking=self._use_locking)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/training/gen_training_ops.py\", line 1302, in resource_apply_adam\n    use_nesterov=use_nesterov, name=name)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 511, in _apply_op_helper\n    preferred_dtype=default_dtype)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1175, in internal_convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1222, in _dense_var_to_tensor\n    return var._dense_var_to_tensor(dtype=dtype, name=name, as_ref=as_ref)  # pylint: disable=protected-access\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1177, in _dense_var_to_tensor\n    return self.value()\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 644, in value\n    return self._read_variable_op()\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 728, in _read_variable_op\n    self._dtype)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 550, in read_variable_op\n    \"ReadVariableOp\", resource=resource, dtype=dtype, name=name)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Error while reading resource variable beta1_power from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/beta1_power/N10tensorflow3VarE does not exist.\n\t [[node Adam/update_dense_1/kernel/ResourceApplyAdam/ReadVariableOp (defined at <ipython-input-15-e61309f3b57c>:12) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Error while reading resource variable beta1_power from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/beta1_power/N10tensorflow3VarE does not exist.\n\t [[{{node Adam/update_dense_1/kernel/ResourceApplyAdam/ReadVariableOp}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-039bac1e1d94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     session_rewards = [generate_session(epsilon=epsilon, \n\u001b[0;32m----> 3\u001b[0;31m                         train=True) for _ in range(500)]\n\u001b[0m\u001b[1;32m      4\u001b[0m     print(\"epoch #{}\\tmean r = {:.3f}\\tepsilon = {:.3f}\"\n\u001b[1;32m      5\u001b[0m           .format(i, np.mean(session_rewards), epsilon))\n",
      "\u001b[0;32m<ipython-input-20-039bac1e1d94>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     session_rewards = [generate_session(epsilon=epsilon, \n\u001b[0;32m----> 3\u001b[0;31m                         train=True) for _ in range(500)]\n\u001b[0m\u001b[1;32m      4\u001b[0m     print(\"epoch #{}\\tmean r = {:.3f}\\tepsilon = {:.3f}\"\n\u001b[1;32m      5\u001b[0m           .format(i, np.mean(session_rewards), epsilon))\n",
      "\u001b[0;32m<ipython-input-17-a7cbb0fd214a>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(t_max, epsilon, train)\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mstates_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mrewards_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_states_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnext_s\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mis_done_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             })\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Error while reading resource variable beta1_power from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/beta1_power/N10tensorflow3VarE does not exist.\n\t [[node Adam/update_dense_1/kernel/ResourceApplyAdam/ReadVariableOp (defined at <ipython-input-15-e61309f3b57c>:12) ]]\n\nCaused by op 'Adam/update_dense_1/kernel/ResourceApplyAdam/ReadVariableOp', defined at:\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/asyncio/base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/asyncio/base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-e61309f3b57c>\", line 12, in <module>\n    train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 413, in minimize\n    name=name)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 612, in apply_gradients\n    update_ops.append(processor.update_op(self, grad))\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 171, in update_op\n    update_op = optimizer._resource_apply_dense(g, self._v)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/training/adam.py\", line 175, in _resource_apply_dense\n    grad, use_locking=self._use_locking)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/training/gen_training_ops.py\", line 1302, in resource_apply_adam\n    use_nesterov=use_nesterov, name=name)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 511, in _apply_op_helper\n    preferred_dtype=default_dtype)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1175, in internal_convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1222, in _dense_var_to_tensor\n    return var._dense_var_to_tensor(dtype=dtype, name=name, as_ref=as_ref)  # pylint: disable=protected-access\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1177, in _dense_var_to_tensor\n    return self.value()\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 644, in value\n    return self._read_variable_op()\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 728, in _read_variable_op\n    self._dtype)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 550, in read_variable_op\n    \"ReadVariableOp\", resource=resource, dtype=dtype, name=name)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/Users/efimovin/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Error while reading resource variable beta1_power from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/beta1_power/N10tensorflow3VarE does not exist.\n\t [[node Adam/update_dense_1/kernel/ResourceApplyAdam/ReadVariableOp (defined at <ipython-input-15-e61309f3b57c>:12) ]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    session_rewards = [generate_session(epsilon=epsilon, \n",
    "                        train=True) for _ in range(500)]\n",
    "    print(\"epoch #{}\\tmean r = {:.3f}\\tepsilon = {:.3f}\"\n",
    "          .format(i, np.mean(session_rewards), epsilon))\n",
    "    \n",
    "    epsilon *= 0.95\n",
    "    epsilon = max(0.1, epsilon)\n",
    "    assert epsilon >= 1e-4, \\\n",
    "    \"убедитесь, что epsilon не становится < 0\"\n",
    "    if np.mean(session_rewards) > 300:\n",
    "        print (\"Принято!\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnregisteredEnv",
     "evalue": "No registered env with id: game-stock-exchange-v0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mspec\u001b[0;34m(self, id)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_specs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'game-stock-exchange-v0'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnregisteredEnv\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-bba2b425fff5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'game-stock-exchange-v0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(self, id)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Making new env: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# We used to have people override _reset/_step rather than\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rl_36/lib/python3.6/site-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mspec\u001b[0;34m(self, id)\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeprecatedEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Env {} not found (valid versions include {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatching_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnregisteredEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No registered env with id: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnregisteredEnv\u001b[0m: No registered env with id: game-stock-exchange-v0"
     ]
    }
   ],
   "source": [
    "env = gym.make('game-stock-exchange-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FSC00yvzTKkH"
   },
   "source": [
    "### Интерпретация результатов\n",
    "\n",
    "\\begin{itemize}\n",
    "\\item mean reward -- среднее вознаграждение за эпизод. В случае корректной реализации, этот показатель будет низким первые 5 эпох и только затем будет возрастать и сойдется на 20-30 эпох в зависииости от архитектуры сети.\n",
    "\\item Если сеть не достигает нужных результатов к концу цикла, попробуйте увеличить число нейронов в скрытом слое или поменяйте $\\epsilon$.\n",
    "\\item epsilon -- обеспечивает стремление агента исследовать среду. Можно искусственно изменять малые значения $\\epsilon$ при низких результатах на 0.1 - 0.5.\n",
    "\\end{itemize}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "sem4_approx.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
