{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov decision process\n",
    "\n",
    "This week's methods are all built to solve __M__arkov __D__ecision __P__rocesses. In the broadest sense, an MDP is defined by how it changes states and how rewards are computed.\n",
    "\n",
    "State transition is defined by $P(s' |s,a)$ - how likely are you to end at state $s'$ if you take action $a$ from state $s$. Now there's more than one way to define rewards, but we'll use $r(s,a,s')$ function for convenience.\n",
    "\n",
    "_This notebook is inspired by the awesome_ [CS294](https://github.com/berkeleydeeprlcourse/homework/blob/36a0b58261acde756abd55306fbe63df226bf62b/hw2/HW2.ipynb) _by Berkeley_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For starters, let's define a simple MDP from this picture:\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/a/ad/Markov_Decision_Process.svg\" width=\"400px\" alt=\"Diagram by Waldoalvarez via Wikimedia Commons, CC BY-SA 4.0\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you Colab, uncomment this please\n",
    "# !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week02_value_based/mdp.py\n",
    "\n",
    "transition_probs = {\n",
    "    's0': {\n",
    "        'a0': {'s0': 0.5, 's2': 0.5},\n",
    "        'a1': {'s2': 1}\n",
    "    },\n",
    "    's1': {\n",
    "        'a0': {'s0': 0.7, 's1': 0.1, 's2': 0.2},\n",
    "        'a1': {'s1': 0.95, 's2': 0.05}\n",
    "    },\n",
    "    's2': {\n",
    "        'a0': {'s0': 0.4, 's2': 0.6},\n",
    "        'a1': {'s0': 0.3, 's1': 0.3, 's2': 0.4}\n",
    "    }\n",
    "}\n",
    "rewards = {\n",
    "    's1': {'a0': {'s0': +5}},\n",
    "    's2': {'a1': {'s0': -1}}\n",
    "}\n",
    "\n",
    "from mdp import MDP\n",
    "mdp = MDP(transition_probs, rewards, initial_state='s0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use MDP just as any other gym environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial state = s0\n",
      "next_state = s2, reward = 0.0, done = False\n"
     ]
    }
   ],
   "source": [
    "print('initial state =', mdp.reset())\n",
    "next_state, reward, done, info = mdp.step('a1')\n",
    "print('next_state = %s, reward = %s, done = %s' % (next_state, reward, done))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but it also has other methods that you'll need for Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mdp.get_all_states = ('s0', 's1', 's2')\n",
      "mdp.get_possible_actions('s1') =  ('a0', 'a1')\n",
      "mdp.get_next_states('s1', 'a0') =  {'s0': 0.7, 's1': 0.1, 's2': 0.2}\n",
      "mdp.get_reward('s1', 'a0', 's0') =  5\n",
      "mdp.get_transition_prob('s1', 'a0', 's0') =  0.7\n"
     ]
    }
   ],
   "source": [
    "print(\"mdp.get_all_states =\", mdp.get_all_states())\n",
    "print(\"mdp.get_possible_actions('s1') = \", mdp.get_possible_actions('s1'))\n",
    "print(\"mdp.get_next_states('s1', 'a0') = \", mdp.get_next_states('s1', 'a0'))\n",
    "print(\"mdp.get_reward('s1', 'a0', 's0') = \", mdp.get_reward('s1', 'a0', 's0'))\n",
    "print(\"mdp.get_transition_prob('s1', 'a0', 's0') = \",\n",
    "      mdp.get_transition_prob('s1', 'a0', 's0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mmdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transition_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m return P(next_state | state, action) \n",
       "\u001b[0;31mFile:\u001b[0m      ~/Documents/Main/Workshop/Course/Practical_RL/week02_value_based/mdp.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mdp.get_transition_prob?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Visualizing MDPs\n",
    "\n",
    "You can also visualize any MDP with the drawing fuction donated by [neer201](https://github.com/neer201).\n",
    "\n",
    "You have to install graphviz for system and for python. For ubuntu just run:\n",
    "\n",
    "1. `sudo apt-get install graphviz`\n",
    "2. `pip install graphviz`\n",
    "3. restart the notebook\n",
    "\n",
    "__Note:__ Installing graphviz on some OS (esp. Windows) may be tricky. However, you can ignore this part alltogether and use the standart vizualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphviz available: False\n"
     ]
    }
   ],
   "source": [
    "from mdp import has_graphviz\n",
    "from IPython.display import display\n",
    "print(\"Graphviz available:\", has_graphviz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_graphviz:\n",
    "    from mdp import plot_graph, plot_graph_with_state_values, \\\n",
    "        plot_graph_optimal_strategy_and_state_values\n",
    "\n",
    "    display(plot_graph(mdp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Iteration\n",
    "\n",
    "Now let's build something to solve this MDP. The simplest algorithm so far is __V__alue __I__teration\n",
    "\n",
    "Here's the pseudo-code for VI:\n",
    "\n",
    "---\n",
    "\n",
    "`1.` Initialize $V^{(0)}(s)=0$, for all $s$\n",
    "\n",
    "`2.` For $i=0, 1, 2, \\dots$\n",
    " \n",
    "`3.` $ \\quad V_{(i+1)}(s) = \\max_a \\sum_{s'} P(s' | s,a) \\cdot [ r(s,a,s') + \\gamma V_{i}(s')]$, for all $s$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's write a function to compute the state-action value function $Q^{\\pi}$, defined as follows\n",
    "\n",
    "$$Q_i(s, a) = \\sum_{s'} P(s' | s,a) \\cdot [ r(s,a,s') + \\gamma V_{i}(s')]$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mdp_get_action_value.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mdp_get_action_value.py\n",
    "\n",
    "def get_action_value(mdp, state_values, state, action, gamma):\n",
    "    \"\"\" Computes Q(s,a) as in formula above \"\"\"\n",
    "    q_value = .0\n",
    "    for next_state in mdp.get_next_states(state, action):\n",
    "        transition_prob = mdp.get_transition_prob(\n",
    "                state, action,next_state  )\n",
    "        reward = mdp.get_reward( state, action, next_state )\n",
    "        \n",
    "        q_value += transition_prob * ( reward + gamma * state_values[next_state] )\n",
    "\n",
    "    return q_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gamma коэффициент дисконтирования\n",
    "# валью функция это просто фиксированное число, \n",
    "# валью функция это функция которая отображает состояние в число, \n",
    "# в мат ожидание реворда. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdp_get_action_value import get_action_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_Vs = {s: i for i, s in enumerate(sorted(mdp.get_all_states()))}\n",
    "assert np.isclose(get_action_value(mdp, test_Vs, 's2', 'a1', 0.9), 0.69)\n",
    "assert np.isclose(get_action_value(mdp, test_Vs, 's1', 'a0', 0.9), 3.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using $Q(s,a)$ we can now define the \"next\" V(s) for value iteration.\n",
    " $$V_{(i+1)}(s) = \\max_a \\sum_{s'} P(s' | s,a) \\cdot [ r(s,a,s') + \\gamma V_{i}(s')] = \\max_a Q_i(s,a)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_state_value(mdp, state_values, state, gamma):\n",
    "    \"\"\" Computes next V(s) as in formula above. Please do not change state_values in process. \"\"\"\n",
    "    if mdp.is_terminal(state):\n",
    "        return 0\n",
    " \n",
    "    v_value = []\n",
    "    for action in mdp.get_possible_actions(state):\n",
    "        for next_state in mdp.get_next_states(state, action):\n",
    "            transition_prob = mdp.get_transition_prob(state, action,next_state)\n",
    "            reward = mdp.get_reward( state, action, next_state )\n",
    "            v_value.append( transition_prob * ( reward + gamma * state_values[next_state] ) )\n",
    "    return max(v_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Vs_copy = dict(test_Vs)\n",
    "assert np.isclose(get_new_state_value(mdp, test_Vs, 's0', 0.9), 1.8)\n",
    "assert np.isclose(get_new_state_value(mdp, test_Vs, 's2', 0.9), 1.08)\n",
    "assert test_Vs == test_Vs_copy, \"please do not change state_values in get_new_state_value\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's combine everything we wrote into a working value iteration algo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 3.50000   |   V(s0) = 0.000   V(s1) = 0.000   V(s2) = 0.000\n",
      "iter    1   |   diff: 0.94500   |   V(s0) = 0.000   V(s1) = 3.500   V(s2) = 0.000\n",
      "iter    2   |   diff: 0.85050   |   V(s0) = 0.000   V(s1) = 3.500   V(s2) = 0.945\n",
      "iter    3   |   diff: 0.53581   |   V(s0) = 0.850   V(s1) = 3.500   V(s2) = 0.945\n",
      "iter    4   |   diff: 0.14467   |   V(s0) = 0.850   V(s1) = 4.036   V(s2) = 0.945\n",
      "iter    5   |   diff: 0.13020   |   V(s0) = 0.850   V(s1) = 4.036   V(s2) = 1.090\n",
      "iter    6   |   diff: 0.08203   |   V(s0) = 0.981   V(s1) = 4.036   V(s2) = 1.090\n",
      "iter    7   |   diff: 0.02215   |   V(s0) = 0.981   V(s1) = 4.118   V(s2) = 1.090\n",
      "iter    8   |   diff: 0.01993   |   V(s0) = 0.981   V(s1) = 4.118   V(s2) = 1.112\n",
      "iter    9   |   diff: 0.01256   |   V(s0) = 1.001   V(s1) = 4.118   V(s2) = 1.112\n",
      "iter   10   |   diff: 0.00339   |   V(s0) = 1.001   V(s1) = 4.130   V(s2) = 1.112\n",
      "iter   11   |   diff: 0.00305   |   V(s0) = 1.001   V(s1) = 4.130   V(s2) = 1.115\n",
      "iter   12   |   diff: 0.00192   |   V(s0) = 1.004   V(s1) = 4.130   V(s2) = 1.115\n",
      "iter   13   |   diff: 0.00052   |   V(s0) = 1.004   V(s1) = 4.132   V(s2) = 1.115\n",
      "Terminated\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "gamma = 0.9            # discount for MDP\n",
    "num_iter = 100         # maximum iterations, excluding initialization\n",
    "# stop VI if new values are this close to old values (or closer)\n",
    "min_difference = 0.001\n",
    "\n",
    "# initialize V(s)\n",
    "state_values = {s: 0 for s in mdp.get_all_states()}\n",
    "\n",
    "if has_graphviz:\n",
    "    display(plot_graph_with_state_values(mdp, state_values))\n",
    "\n",
    "for i in range(num_iter):\n",
    "\n",
    "    # Compute new state values using the functions you defined above.\n",
    "    # It must be a dict {state : float V_new(state)}\n",
    "    new_state_values = {s: get_new_state_value(mdp, state_values, s, gamma) for s in mdp.get_all_states()}\n",
    "\n",
    "    assert isinstance(new_state_values, dict)\n",
    "\n",
    "    # Compute difference\n",
    "    diff = max(abs(new_state_values[s] - state_values[s])\n",
    "               for s in mdp.get_all_states())\n",
    "    print(\"iter %4i   |   diff: %6.5f   |   \" % (i, diff), end=\"\")\n",
    "    print('   '.join(\"V(%s) = %.3f\" % (s, v) for s, v in state_values.items()))\n",
    "    state_values = new_state_values\n",
    "\n",
    "    if diff < min_difference:\n",
    "        print(\"Terminated\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_graphviz:\n",
    "    display(plot_graph_with_state_values(mdp, state_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final state values: {'s0': 1.0036873390859589, 's1': 4.132323023624154, 's2': 1.1157272163785215}\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-aa21b33efbf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Final state values:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m's0'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m3.781\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m's1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m7.294\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m's2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m4.202\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Final state values:\", state_values)\n",
    "\n",
    "assert abs(state_values['s0'] - 3.781) < 0.01\n",
    "assert abs(state_values['s1'] - 7.294) < 0.01\n",
    "assert abs(state_values['s2'] - 4.202) < 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use those $V^{*}(s)$ to find optimal actions in each state\n",
    "\n",
    " $$\\pi^*(s) = argmax_a \\sum_{s'} P(s' | s,a) \\cdot [ r(s,a,s') + \\gamma V_{i}(s')] = argmax_a Q_i(s,a)$$\n",
    " \n",
    "The only difference vs V(s) is that here we take not max but argmax: find action such with maximum Q(s,a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_action(mdp, state_values, state, gamma=0.9):\n",
    "    \"\"\" Finds optimal action using formula above. \"\"\"\n",
    "    if mdp.is_terminal(state):\n",
    "        return None\n",
    "    \n",
    "    q_value = {}\n",
    "    \n",
    "    for action in mdp.get_possible_actions(state):\n",
    "        q_value[action] = get_action_value(mdp, state_values, state, action, gamma)\n",
    "\n",
    "    return max(q_value, key=q_value.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_optimal_action(mdp, state_values, 's0', gamma) == 'a1'\n",
    "assert get_optimal_action(mdp, state_values, 's1', gamma) == 'a0'\n",
    "assert get_optimal_action(mdp, state_values, 's2', gamma) == 'a1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_graphviz:\n",
    "    try:\n",
    "        display(plot_graph_optimal_strategy_and_state_values(mdp, state_values))\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Run the cell that starts with \\\"%%writefile mdp_get_action_value.py\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average reward:  0.4694\n"
     ]
    }
   ],
   "source": [
    "# Measure agent's average reward\n",
    "\n",
    "s = mdp.reset()\n",
    "rewards = []\n",
    "for _ in range(10000):\n",
    "    s, r, done, _ = mdp.step(get_optimal_action(mdp, state_values, s, gamma))\n",
    "    rewards.append(r)\n",
    "\n",
    "print(\"average reward: \", np.mean(rewards))\n",
    "\n",
    "assert(0.40 < np.mean(rewards) < 0.55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frozen lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*FFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mdp import FrozenLakeEnv\n",
    "mdp = FrozenLakeEnv(slip_chance=0)\n",
    "\n",
    "mdp.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(mdp, state_values=None, gamma=0.9, num_iter=1000, min_difference=1e-5):\n",
    "    \"\"\" performs num_iter value iteration steps starting from state_values. Same as before but in a function \"\"\"\n",
    "    state_values = state_values or {s: 0 for s in mdp.get_all_states()}\n",
    "    for i in range(num_iter):\n",
    "\n",
    "        # Compute new state values using the functions you defined above. It must be a dict {state : new_V(state)}\n",
    "        new_state_values = {s: get_new_state_value(mdp, state_values, s, gamma) for s in mdp.get_all_states()}\n",
    "\n",
    "        assert isinstance(new_state_values, dict)\n",
    "\n",
    "        # Compute difference\n",
    "        diff = max(abs(new_state_values[s] - state_values[s])\n",
    "                   for s in mdp.get_all_states())\n",
    "\n",
    "        print(\"iter %4i   |   diff: %6.5f   |   V(start): %.3f \" %\n",
    "              (i, diff, new_state_values[mdp._initial_state]))\n",
    "\n",
    "        state_values = new_state_values\n",
    "        if diff < min_difference:\n",
    "            break\n",
    "\n",
    "    return state_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 1.00000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.90000   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.81000   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.72900   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.65610   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.59049   |   V(start): 0.590 \n",
      "iter    6   |   diff: 0.00000   |   V(start): 0.590 \n"
     ]
    }
   ],
   "source": [
    "state_values = value_iteration(mdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*FFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "down\n",
      "\n",
      "SFFF\n",
      "*HFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "down\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "*FFH\n",
      "HFFG\n",
      "\n",
      "right\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "F*FH\n",
      "HFFG\n",
      "\n",
      "down\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H*FG\n",
      "\n",
      "right\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF*G\n",
      "\n",
      "right\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = mdp.reset()\n",
    "mdp.render()\n",
    "for t in range(100):\n",
    "    a = get_optimal_action(mdp, state_values, s, gamma)\n",
    "    print(a, end='\\n\\n')\n",
    "    s, r, done, _ = mdp.step(a)\n",
    "    mdp.render()\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's visualize!\n",
    "\n",
    "It's usually interesting to see what your algorithm actually learned under the hood. To do so, we'll plot state value functions and optimal actions at each VI step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def draw_policy(mdp, state_values):\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    h, w = mdp.desc.shape\n",
    "    states = sorted(mdp.get_all_states())\n",
    "    V = np.array([state_values[s] for s in states])\n",
    "    Pi = {s: get_optimal_action(mdp, state_values, s, gamma) for s in states}\n",
    "    plt.imshow(V.reshape(w, h), cmap='gray', interpolation='none', clim=(0, 1))\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticks(np.arange(h)-.5)\n",
    "    ax.set_yticks(np.arange(w)-.5)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    Y, X = np.mgrid[0:4, 0:4]\n",
    "    a2uv = {'left': (-1, 0), 'down': (0, -1), 'right': (1, 0), 'up': (0, 1)}\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            plt.text(x, y, str(mdp.desc[y, x].item()),\n",
    "                     color='g', size=12,  verticalalignment='center',\n",
    "                     horizontalalignment='center', fontweight='bold')\n",
    "            a = Pi[y, x]\n",
    "            if a is None:\n",
    "                continue\n",
    "            u, v = a2uv[a]\n",
    "            plt.arrow(x, y, u*.3, -v*.3, color='m',\n",
    "                      head_width=0.1, head_length=0.1)\n",
    "    plt.grid(color='b', lw=2, ls='-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 0\n",
      "iter    0   |   diff: 1.00000   |   V(start): 0.000 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALQAAAC0CAYAAAA9zQYyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAALM0lEQVR4nO3dbWxVhR3H8e/pvbRreWoNFRSBQrMCGgaloESmi2bKFh5sdItACC6iUIwhGBOdxBeQxjinDl45mSEQXswaIWaJMozOauZ0iSgyH4ZIy4OLCl1ROgVLa89e3N4+23t6e57un9+nOZHee8+9v57+LOeUe87fcV0XESvyog4g4icVWkxRocUUFVpMUaHFlGSmBziOsxZYm/psZBXMCDiSiBfv4rqu0/dWZyi/tnOceS6862ss/6S/jn5fY4woo58GKrR2OcQUFVpMUaHFFBVaTFGhxRQVWkxRocUUFVpMUaHFFBVaTFGhxRQVWkxRocUUFVpMyfh+6ECUADcDk4EC4BxwGngJ+CqSRL1tBIoHuP1p4MuQs/yQuGeMKF80hb4dmAA0As3AGGAKMJp4FDrtE3rn+TaqIIOIe8aQ8w270A4OC1nISlayla18yqeDr1BIqszngd09bk8Q2A5QPvksZSk3cAMP8iDfet2qB4HDwWTqq4QSVrGKS7iELWzxvmKIGcsoYy1rOcQhnuM5byuFmA+GUeh0kWuooYQSkiSZwpTMhW7tXAqBGuAYcAJoANqyTTOwfPJZxjJWs5okSRIkGMUo74WuBMp6fL7f33zQXeTFLMbBoZXWoT1BCBnTRZ7LXEYwggQJ74UOIV9PWZ+CdRu3cS/3ZvWi9VfV8+TSJ/n2Rz2K9Q3wZ+DzrJ6SgU4dqqWWa7mWvCH+6F++cTmnik/1v2NzttnS+mfcy17GMpYEiSE9U1gZxzOeOurooGNI2zG4fN0GOgUr65/Qr/AK4xhHNdU4nV/8HvbwJm9mXvkjmPjJRI5OOUrHlA6YC4wCfgY8m22i/raznQ46uIZrSJDAxaWWWppoGnS9ZpoBmFA3gS8PB3uEVUst61nPJCZRSCFttLGBDRnXS2csqSvhq8PBHXg00cSjPMrd3E1R50cDDTzBE57yTaybyLnD5/gqrIMj13U9L1DlkvpfuGsZwxh3Hevcfexzqwa4v9+Sh8vkPrctwGUzLndkWHfQxe1c+t83iUnuFra4L/GSW0xx5ufa2JlnxnDyDC3jHOa429nu7mKXt+cKOWMeee7N3Ow+z/Pu/dwfYb7uZaCO+nbWdx55dNCR+UnygU1AE/AFqf3mmUAR8Dfg757j9JH+On74bGXPGdO/cqrD5wOa3M8Yfb5uvu5y9OXpiwRoB94mdaDwY2AE0AK8A/zDrzQD85wxQnHPGPd8ui5HqJTRT7ouh5inQospKrSYokKLKSq0mKJCiykqtJiiQospKrSYokKLKSq0mKJCiykqtJiiQospWbwf2vvbTaMR93ygjH74oRMQMq3mOGsdxzngOM4BMpyLJxI1vcE/VMroJ73BX8xTocUUFVpMUaHFFBVaTFGhxRQVWkxRocUUFVpMUaHFFBVaTFGhxRQVWkxRocWU8OcU5srAyJ5Xni8DfgN8B/wuklT9aTsOyLdCJ0nSTrv3FeI+MDIi2o7DM+xCp+fsLWEJD/Mw7/COtxVDHsgYd/OYx3rWkyTJHdzhfUVtx16yLvRYxrKa1SxmMQAuLvOZzwUuDLrex3xMG22MqRzDN2XfdM/sCHgg45D1HBg5JriXqaKKe7iHy7iMQgr5nu+ZzeyM66W3Y2FlIefLznffcZFux7SsC30jN3Irt/a67dedH4NZznJOcYqW6S2974jbN2J6OC/zEA9RTHHX4M0ECbaxLeN66e14fvr53ndcpNsxLetCv8ALfMEX1FBDKaUkSfI4j/Mqr3p7ggDHfflioIOZANzJnaxgBdVUk0cerbSyjGXen0DbsZdh7UP/s/NjAQtYyUqOccyvXBeNFlrYznae5VlWsIJSSqOOlNN8+S1HutiSvXSxZXj0Dytiiq7LESpl9JOuyyHmqdBiigotpqjQYooKLaao0GKKCi2mqNBiigotpqjQYooKLaao0GKKCi2mqNBiigZvRkIZh0+DN+UioDf4h0oZ/aQ3+It5KrSYokKLKSq0mKJCiykqtJiiQospKrSYokKLKSq0mKJCiykqtJiiQospKrSYosGbA1HG4cv1wZsVVHCUo91j2jIJeWBkggRTmcpRjnpfKReGWuZCxhANu9DzmU8NNUxjGrXU8hqveVsxpIGRCRIsYhF3cRcllHA7t3Oa095WzoWhlrmQMURZF7qccjaxqWtgZCutbGQjN3HToOs9xmN8zddUVFZwsuwk3/Fd6o4A5utdx3Xcx30UUEARRQBsZjNnOesp47TKaRwvOx7f4aBAQWUBrWWt3TfELWOuDN68giuYzOSub3aSJAUUsIAFg65XQAEAR6Yf6X1HAN+IWcxiFKPI63HsO5OZGddLZ2yc3tj7jriVBWid3tr7hrhlzJXBm2/wBh/yIatZzSIWkSDBIzwSq8GbT/EUL/My61jHLGaRJMkqVnGKU96eIO5DLYHaulr2HN7DIQ5FHWVguTR4s5lmtrKV3exmKUt5n/f9yuWbBhp4gAcop5yFLOQMZ6KOJAHy5bcczTSzi11+PFVgGjo/xDb9w4rY4rqu5wWqXFIXbojh4nYuUecIN2M99e5sZsc6Y1DLQB3VT2gxRYUWU1RoMUWFFlNUaDFFhc5RIxnJeMYDUEopJZREnCgedDndUPmXcRvbmMlM8smnnXbaaGMZy2infZjPnAvbMUWX0zWknvqu8jo4HOSgD2XOfSp0jtrHPtpoA6CNNp7hmYgTxYMKnaPaaGMnO+mgg/d4j+McjzpSLIR/TqH4Zh/7qKKKHeyIOkps6KAwVMroJx0UinkqtJiiwZuRUMbh0+BNuQjooDBUqYxD2OShc7o2X5y3Y4oOCsU8FVpMUaHFFBVaTFGhxRQVWkxRocUUFVpMUaHFFBVaTFGhxRQVWkxRocWUcM8pjGh23ZDFfQYgULatjBNnT/S7/eC6g8yZMCeCRAOYCPwUmAQUAueA08AB4N/BvKROkh1MDswAXFKxhPKS8q7PS4tKI0zTw5XAr0jtAzQBR4ACUiWfhQodiSHOABzHOK7nevazn3OcCyxWT2sq11A9o9rz48++fZbzDee5dPml5CUD2uMcASwhVeYPgBegax6rA4wL5mUhqkKHPLsuaz1zQsaRaQtZyHrWs4Y11FHHXvYGXuwdB3fw+vHXuz7f9ottgz7+5KMnOfPXMzQ+2Mi0x6YFU+xJ0DkWEt6AXsOFXQI98SmaQoc8uy5rfXLW76/PuEo77RRRxEpWsoIVbGJToNPBXjzyYq/Pq3/p7af1hc8vcKTmCI2/bWTeu/PIH5/vX6iRPf78ded/f05qfzpts38v11M0hQ55dl22SutKqT1cSz6pb/Yxjg36+KlM7RpE2kEHzTTTQkugGXdO2smVf7iy+4arBn/8uY86/8ZwgA4omlGEk+/z6VY9jzXGAGeAk8C/gJ/4+1J9aR96EE00UUON58ffwi1sYAOf8RlP8zRv8VaA6VKKry3m6juv9vz4D275gOYXmym+oZjy35czeu5o/0N9Ruo3GkXAdcBfSB0UtqBC55L97OcEJ2I5gDSt4o8VXNh8gdGVARQ5rQ3YB9xK6jjkMuA/wNjgXjJNhfZRK62xLjNAweUFFFxeEPwLfUjqJ/JCUgeJlaR2RY4CHwf3srqMQah0GQM/6TIGYp4KLaao0GKKCi2mqNBiigotpqjQYooKLaao0GKKCi2mqNBiigotpqjQYooKLaao0GLKEN8P7fyP1NUq4moc8N+oQ2SgjP6Y4rpuv4uQDPWMlU9c153nUyDfOY5zIM75QBmDpl0OMUWFFlOGWug/BZLCP3HPB8oYqCEdFIrEnXY5xBQVWkxRocUUFVpMUaHFlP8DqtHJwqkdaCwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 1\n",
      "iter    0   |   diff: 0.90000   |   V(start): 0.000 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 2\n",
      "iter    0   |   diff: 0.81000   |   V(start): 0.000 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALQAAAC0CAYAAAA9zQYyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAMW0lEQVR4nO3dfWxV9R3H8fe5ve2lLbRUS0EqtkoEhjAtViSgTgzxEaRB2SgaNh9AlrhMZhxmM4PYGTfBhz9cZgWjWyLUhIQsYRsiggsuzADrGEMBoSpPBVqgFijQ0nv2x70tLb20t7f33HPOz8+rabjn9p7ebw8fDr9zes7va9m2jYgpAm4XIJJMCrQYRYEWoyjQYhQFWowS7OkFlmXNA+ZFlrJvhlEOlyQSj23Ytm1d+qzVm9N2llVqw7aklpU8bT9Hl5/RQ1RjMsUKtIYcYhQFWoyiQItRFGgxigItRlGgxSgKtBhFgRajKNBiFAVajKJAi1EUaDGKAi1GUaDFKD1eD+2IPOBu4BogBDQBx4C/AiddqaizZ4CBMZ5/CziS4loux+s1ulSfO4H+ETAEqAGOAzlAETAAbwS6zW4613PGrUK64fUaU1xfnwNtYTGJScxmNq/zOl/yZfcrZBIJ81ngzx2eT8OxAVAGGUxjGpOZzEIWciberVoN7HKmpqRJYY3FFDOPeWxnOx/wQXwrpXgbJhzotiDPZz555BEkSBFFPQf6fPQzE5gPfAV8A+wDWhKtJrYMMniQB5nDHIIESSON/vSPP9AlQHGH5bXJrS8pUlBjW5DHMY500kkjLf5Ap3gbJnwL1kM8xNM8ndCbbrxhI69Oe5Uz/ToE6zSwAjic0Lck1q1DFVQwkYkEernrn/XMLI4OPNr1C4sTra1NEm9vutwYdXFfv3HnGgczmCqqCBPu1XZ0bhteFOsWrIT30B/xEfnkU0YZVvSHX8UqPuXTnlfeCYW7C9lbtJdwURjGAf2BHwArE62oq0oqCRPmVm4ljTRsbCqooI66btc7znEAhlQN4cguLxxhXV5FVQWrdq1iO9sd+f511PEyLzOXuWRFP/axj6Us7Xa9tm1YWFVI064mTqbo4CjhQDfSSCWVrGQl5ZQznelUU82ungZMAeBqYD+RYcY+Imc57gUyEq0mtoMcZBGLGMYwnuRJSillBztooCGu9Y944nSBu8KEWcc61rOeKUxhLnP5gi96/nuOOsQhhyvsrM8HhW3BXsYywoTje8fHgTqglsi4+XvRr9X0tZrYDnCARSwiQCC+GqWLjsH28jZM2mm7uH/IC8BmIgcK1wPpQCOwBfhnsqqJzct/EX7h+W1o23bcn3CzTeSowYOfdvTT7TpSW+NGNto3cqOna3TqM1ZG9atvMYoCLUZRoMUoCrQYRYEWoyjQYhR3Lh+VPpvJTEopBWABC9jJTpayFBvb5crcpUD71BjGtAe6iCJyyCFAgFZaXa7MXRpy+NRyltMSvd62iSaWs/w7H2ZQoH3rAAf4jM8IE+Y85/mQD90uyRMUaB9bzvL2P7V3jlCPlZRKfo0FFFBPfRIvGvLDdoxI6gX+4g3HOOZ2CZ6iIYcYJYE9tNfPc3q9PlCNyRB7SNTjHtqyrHmWZW21LGsrPdyLJ+I2HRSmVKTG6ur/uFzH5ZWU3BR95OXtGKHGm2I8BVqMokCLURRoMYoCLUZRoMUoCrQYRYEWoyjQYhQFWoyiQItRFGgxigItRlGgxSipvwXLLw0jq7jYjqwY+AlwDvidK1V1cf+6+6k9W9vl+ao7qxiZO9KFii7h0nZMWqCDBLnAhfhX8HrDSJ+4Y/AdXJ19dftyXkaei9W4r8+BziOPR3mUqUzlBV5gC1viW9EPTS19oKyojMlXTXa7DM9IONC55DKHOTzAAwDY2NzCLTTT3O16n/M5LbSQU5LD6eLTF2+/91pTy44NI3NcrKMHq79ezdb6re3Lz419zsVqYkjxdkw40HdxFzOY0em5mdGP7sxiFkc5SuPIxs5f8FqgPTAMjcemY5voOJOB5wKd4u2YcKBXs5paapnPfAYxiCBBlrCE9ayP7xt0PFjwolgHMx5UUVXBPc/eQ3pputulxJbi7dinMfS/oh8TmMBsZvMVXyWrLpGEJOUsR1uwRdymX6yIUTQvR0olf16OhpIGspdlJ20MrXk5RDxEgRajKNBiFAVajKJAi1EUaDGKAu1TZ54/Q8MdDZHHT52hsawRu8Xrk5Q7T4H2qUBBIHKhPEAYSEcdc1CgfSv0WAjSoguZkPmLTCzL+78McZoC7VOBvAChmSEIQKAwQHCCds+gQPta6LEQVp5F5rPaO7fRP2sfC+QFyF2f63YZnqI9tBhFgRajJHD56NaeXyjiOCuxy0fVeFP8xLgL/P3Q1PLw4a4zHnnF0KFXRR95/6yJLvAX4ynQYhQFWoyiQItRFGgxigItRlGgxSgKtBhFgRajKNBiFAVajKJAi1EUaDGKAi1GUePNGDzf1BIYv2I8B08f7PL8uhnrGJM/xoWKLuH3xpu9lkDjzRGMYC97L7aCc5gfmlpOuWYKxTnF7ctXZl7pXjEe4F6ge9l481qupZJK6qjjbd5mAxscD7YfmlqWjyrnvuL73C7DM1wLdKAkQElxCSFCAExbO63b1w9mMGHCDGIQC1jAPOaxhCXxd65NwOo9q9lydAtWWuTGCM/1AARW/HsFmw9vbl9+ceKLLlYTg18ab/ZVeGSYbR1u53pp7Utxr5sR/RjNaEcDvalhEzRcXPZioD+u/xjqLy57LtB+abzZZ5c03pxM9/+1D2c4b/EWrbSyhS0sYxn72e9oiRVVFdx55Z30f7O/o+/TFxVVFZT/tpysiVlulxKbnxpvptIhDvE+77OBDY4HWfzLN4E+xzne4z23yxCP0y9WxCial6MbDSUNBCcFkzaGdmJejt1DdzNs1bCkjaE1L4eIhyjQYhQFWoyiQItRFGgxigIdg33epvVwa+Rxg024NjVX9/VGa2MrLQdaAGipbeFC3QWXK/IGBTqGc++e49SDpwBo3dlK4/2NXNjlrcAc+vEham6vAeDIgiPUTKjBblbjTQU6hvTJ6Z1+h2rlWaQNT7v8Ci4YMH0AVjB6GjYMWbdlYWV4/9yx0xToGIIjgwRLgpGtkwn9ftYPK91bYcktz8UKRWqyMiwG/WqQyxV5gwJ9Gf1+3g8CYPWzyJia4XY5XQRCAfKfy4cAZN2eRWhkyO2SPME3FyelWnBUkIyZGQTHBT23d26TW55L06Ym8hfmu12KZyjQ3cj6pUevMY4KhAIUvlPodhmeoiGHGEWBFqOo8ab4lBpvyneAcRf4+6GpZS82ecpZ7fs8b57Z6UgX+IvxFGgxigItRlGgxSgKtBhFgRajKNBiFAVajKJAi1EUaDGKAi1GUaDFKAq0GCW1t2C51LuutzzfAxAofqOYb779psvz1U9Vc9OQm1yoKIZC4DZgGJAJNAHHiFxS/4Uzb6l7Crvhhx6AU0dMZXje8PblQVkemc5gNPAwkTFAHbAHCBEJ+VgUaDf0tgdgS20Lp9acIndWLmkDUjMxzRMlT1A2qizu13+7+VvO7jtLwawCAkGHRpzpwFQiYd4BrIb2lpIW4OBN6u4EOsW96xK1ctfKXvUAPP3haeperKP+lXqu+OkV5M3NczzY71S/wydff9K+/Ma9b3T7+v0v7+fE309Qs7CG635/nTPBHga03TD/D+jUH9XG0Ruf3Am0N9pl92j9/vWdlh95+JGeV0oD+4zNiTdPcOIPJyj8UyHZt2U7VCGs2bOm03LZffHtrZsPN7Nn/h5qnq+hdFspGYOTOJlOxx+3rc/jFCLj6TaLk/d2HbkT6BT3rktU5Q2VjK0Yi30+es9UD/8Qm3c3R/6bbQXSIFgQJO0KZ/fQ7w57l9Gvjb74xA3dv75pZ1PkgUVkTrxRDsyJ17Fvew5wAtgP/Bf4fnLf6lIaQ3cjWBikeG1x3K8/+d5Jjv36GOnXplPwmwKy787Gspy9N2/gxIGMf3x83K/fMX0Hx9ccZ+DkgQx/ZTgDxg1IflEHiJzRyAJuB/5C5KCwEQXaT3J/mEvo+hCZEzMdD3KiRvxxBM2LmxlQ4kCQ27QAfwNmEDleugo4COQ695ZtFOgkCmQFyJrk7enDQkNDhIamYGLH/xHZI08icpBYQmQoshf43Lm31TQGKaRpDJJL0xiI8RRoMYoCLUZRoMUoCrQYRYEWoyjQYhQFWoyiQItRFGgxigItRlGgxSgKtBhFgRajKNBilF5eD22dAnY7V06f5QP1bhfRA9WYHEW2bXeZhKS3d6zstm27NEkFJZ1lWVu9XB+oRqdpyCFGUaDFKL0N9NuOVJE8Xq8PVKOjenVQKOJ1GnKIURRoMYoCLUZRoMUoCrQY5f/1cjAUmlFjiQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 3\n",
      "iter    0   |   diff: 0.72900   |   V(start): 0.000 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 4\n",
      "iter    0   |   diff: 0.65610   |   V(start): 0.000 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 5\n",
      "iter    0   |   diff: 0.59049   |   V(start): 0.590 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 6\n",
      "iter    0   |   diff: 0.00000   |   V(start): 0.590 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 7\n",
      "iter    0   |   diff: 0.00000   |   V(start): 0.590 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 8\n",
      "iter    0   |   diff: 0.00000   |   V(start): 0.590 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 9\n",
      "iter    0   |   diff: 0.00000   |   V(start): 0.590 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state_values = {s: 0 for s in mdp.get_all_states()}\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"after iteration %i\" % i)\n",
    "    state_values = value_iteration(mdp, state_values, num_iter=1)\n",
    "    draw_policy(mdp, state_values)\n",
    "# please ignore iter 0 at each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 29\n",
      "iter    0   |   diff: 0.00000   |   V(start): 0.058 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "mdp = FrozenLakeEnv(map_name='8x8', slip_chance=0.1)\n",
    "state_values = {s: 0 for s in mdp.get_all_states()}\n",
    "\n",
    "for i in range(30):\n",
    "    clear_output(True)\n",
    "    print(\"after iteration %i\" % i)\n",
    "    state_values = value_iteration(mdp, state_values, num_iter=1)\n",
    "    draw_policy(mdp, state_values)\n",
    "    sleep(0.5)\n",
    "# please ignore iter 0 at each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Massive tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 1.00000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.90000   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.81000   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.72900   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.65610   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.59049   |   V(start): 0.590 \n",
      "iter    6   |   diff: 0.00000   |   V(start): 0.590 \n",
      "average reward:  1.0\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "mdp = FrozenLakeEnv(slip_chance=0)\n",
    "state_values = value_iteration(mdp)\n",
    "\n",
    "total_rewards = []\n",
    "for game_i in range(1000):\n",
    "    s = mdp.reset()\n",
    "    rewards = []\n",
    "    for t in range(100):\n",
    "        s, r, done, _ = mdp.step(\n",
    "            get_optimal_action(mdp, state_values, s, gamma))\n",
    "        rewards.append(r)\n",
    "        if done:\n",
    "            break\n",
    "    total_rewards.append(np.sum(rewards))\n",
    "\n",
    "print(\"average reward: \", np.mean(total_rewards))\n",
    "assert(1.0 <= np.mean(total_rewards) <= 1.0)\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 0.90000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.72900   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.59049   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.47830   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.38742   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.31381   |   V(start): 0.314 \n",
      "iter    6   |   diff: 0.00000   |   V(start): 0.314 \n",
      "average reward:  0.892\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# Measure agent's average reward\n",
    "mdp = FrozenLakeEnv(slip_chance=0.1)\n",
    "state_values = value_iteration(mdp)\n",
    "\n",
    "total_rewards = []\n",
    "for game_i in range(1000):\n",
    "    s = mdp.reset()\n",
    "    rewards = []\n",
    "    for t in range(100):\n",
    "        s, r, done, _ = mdp.step(\n",
    "            get_optimal_action(mdp, state_values, s, gamma))\n",
    "        rewards.append(r)\n",
    "        if done:\n",
    "            break\n",
    "    total_rewards.append(np.sum(rewards))\n",
    "\n",
    "print(\"average reward: \", np.mean(total_rewards))\n",
    "assert(0.8 <= np.mean(total_rewards) <= 0.95)\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 0.75000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.50625   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.34172   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.23066   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.15570   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.10509   |   V(start): 0.105 \n",
      "iter    6   |   diff: 0.00000   |   V(start): 0.105 \n",
      "average reward:  0.652\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# Measure agent's average reward\n",
    "mdp = FrozenLakeEnv(slip_chance=0.25)\n",
    "state_values = value_iteration(mdp)\n",
    "\n",
    "total_rewards = []\n",
    "for game_i in range(1000):\n",
    "    s = mdp.reset()\n",
    "    rewards = []\n",
    "    for t in range(100):\n",
    "        s, r, done, _ = mdp.step(\n",
    "            get_optimal_action(mdp, state_values, s, gamma))\n",
    "        rewards.append(r)\n",
    "        if done:\n",
    "            break\n",
    "    total_rewards.append(np.sum(rewards))\n",
    "\n",
    "print(\"average reward: \", np.mean(total_rewards))\n",
    "assert(0.6 <= np.mean(total_rewards) <= 0.7)\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 0.80000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.57600   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.41472   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.29860   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.21499   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.15479   |   V(start): 0.000 \n",
      "iter    6   |   diff: 0.11145   |   V(start): 0.000 \n",
      "iter    7   |   diff: 0.08024   |   V(start): 0.000 \n",
      "iter    8   |   diff: 0.05778   |   V(start): 0.000 \n",
      "iter    9   |   diff: 0.04160   |   V(start): 0.000 \n",
      "iter   10   |   diff: 0.02995   |   V(start): 0.000 \n",
      "iter   11   |   diff: 0.02156   |   V(start): 0.000 \n",
      "iter   12   |   diff: 0.01553   |   V(start): 0.000 \n",
      "iter   13   |   diff: 0.01118   |   V(start): 0.011 \n",
      "iter   14   |   diff: 0.00000   |   V(start): 0.011 \n",
      "average reward:  0.451\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-f9be64b0d59d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average reward: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_rewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.6\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_rewards\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Well done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Measure agent's average reward\n",
    "mdp = FrozenLakeEnv(slip_chance=0.2, map_name='8x8')\n",
    "state_values = value_iteration(mdp)\n",
    "\n",
    "total_rewards = []\n",
    "for game_i in range(1000):\n",
    "    s = mdp.reset()\n",
    "    rewards = []\n",
    "    for t in range(100):\n",
    "        s, r, done, _ = mdp.step(\n",
    "            get_optimal_action(mdp, state_values, s, gamma))\n",
    "        rewards.append(r)\n",
    "        if done:\n",
    "            break\n",
    "    total_rewards.append(np.sum(rewards))\n",
    "\n",
    "print(\"average reward: \", np.mean(total_rewards))\n",
    "assert(0.6 <= np.mean(total_rewards) <= 0.8)\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW Part 1: Value iteration convergence\n",
    "\n",
    "### Find an MDP for which value iteration takes long to converge  (0.5 pts)\n",
    "\n",
    "When we ran value iteration on the small frozen lake problem, the last iteration where an action changed was iteration 6--i.e., value iteration computed the optimal policy at iteration 6. Are there any guarantees regarding how many iterations it'll take value iteration to compute the optimal policy? There are no such guarantees without additional assumptions--we can construct the MDP in such a way that the greedy policy will change after arbitrarily many iterations.\n",
    "\n",
    "Your task: define an MDP with at most 3 states and 2 actions, such that when you run value iteration, the optimal action changes at iteration >= 50. Use discount=0.95. (However, note that the discount doesn't matter here--you can construct an appropriate MDP with any discount.)\n",
    "\n",
    "Note: value function must change at least once after iteration >=50, not necessarily change on every iteration till >=50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_probs = {\n",
    "    < YOUR CODE >\n",
    "}\n",
    "rewards = {\n",
    "    < YOUR CODE >\n",
    "}\n",
    "\n",
    "from mdp import MDP\n",
    "from numpy import random\n",
    "mdp = MDP(transition_probs, rewards, initial_state=random.choice(tuple(transition_probs.keys())))\n",
    "# Feel free to change the initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_values = {s: 0 for s in mdp.get_all_states()}\n",
    "policy = np.array([get_optimal_action(mdp, state_values, state, gamma)\n",
    "                   for state in sorted(mdp.get_all_states())])\n",
    "\n",
    "for i in range(100):\n",
    "    print(\"after iteration %i\" % i)\n",
    "    state_values = value_iteration(mdp, state_values, num_iter=1)\n",
    "\n",
    "    new_policy = np.array([get_optimal_action(mdp, state_values, state, gamma)\n",
    "                           for state in sorted(mdp.get_all_states())])\n",
    "\n",
    "    n_changes = (policy != new_policy).sum()\n",
    "    print(\"N actions changed = %i \\n\" % n_changes)\n",
    "    policy = new_policy\n",
    "\n",
    "# please ignore iter 0 at each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value iteration convervence proof (0.5 pts)\n",
    "**Note:** Assume that $\\mathcal{S}, \\mathcal{A}$ are finite.\n",
    "\n",
    "Update of value function in value iteration can be rewritten in a form of Bellman operator:\n",
    "\n",
    "$$(TV)(s) = \\max_{a \\in \\mathcal{A}}\\mathbb{E}\\left[ r_{t+1} + \\gamma V(s_{t+1}) | s_t = s, a_t = a\\right]$$\n",
    "\n",
    "Value iteration algorithm with Bellman operator:\n",
    "\n",
    "---\n",
    "&nbsp;&nbsp; Initialize $V_0$\n",
    "\n",
    "&nbsp;&nbsp; **for** $k = 0,1,2,...$ **do**\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $V_{k+1} \\leftarrow TV_k$\n",
    "\n",
    "&nbsp;&nbsp;**end for**\n",
    "\n",
    "---\n",
    "\n",
    "In [lecture](https://docs.google.com/presentation/d/1lz2oIUTvd2MHWKEQSH8hquS66oe4MZ_eRvVViZs2uuE/edit#slide=id.g4fd6bae29e_2_4) we established contraction property of bellman operator:\n",
    "\n",
    "$$\n",
    "||TV - TU||_{\\infty} \\le \\gamma ||V - U||_{\\infty}\n",
    "$$\n",
    "\n",
    "For all $V, U$\n",
    "\n",
    "Using contraction property of Bellman operator, Banach fixed-point theorem and Bellman equations prove that value function converges to $V^*$ in value iterateion$\n",
    "\n",
    "*<-- Your proof here -->*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus. Asynchronious value iteration (2 pts)\n",
    "\n",
    "Consider the following algorithm:\n",
    "\n",
    "---\n",
    "\n",
    "Initialize $V_0$\n",
    "\n",
    "**for** $k = 0,1,2,...$ **do**\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; Select some state $s_k \\in \\mathcal{S}$    \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $V(s_k) := (TV)(s_k)$\n",
    "\n",
    "**end for**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Note that unlike common value iteration, here we update only a single state at a time.\n",
    "\n",
    "**Homework.** Prove the following proposition:\n",
    "\n",
    "If for all $s \\in \\mathcal{S}$, $s$ appears in the sequence $(s_0, s_1, ...)$ infinitely often, then $V$ converges to $V*$\n",
    "\n",
    "*<-- Your proof here -->*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW Part 2: Policy iteration\n",
    "\n",
    "## Policy iteration implementateion (2 pts)\n",
    "\n",
    "Let's implement exact policy iteration (PI), which has the following pseudocode:\n",
    "\n",
    "---\n",
    "Initialize $\\pi_0$   `// random or fixed action`\n",
    "\n",
    "For $n=0, 1, 2, \\dots$\n",
    "- Compute the state-value function $V^{\\pi_{n}}$\n",
    "- Using $V^{\\pi_{n}}$, compute the state-action-value function $Q^{\\pi_{n}}$\n",
    "- Compute new policy $\\pi_{n+1}(s) = \\operatorname*{argmax}_a Q^{\\pi_{n}}(s,a)$\n",
    "---\n",
    "\n",
    "Unlike VI, policy iteration has to maintain a policy - chosen actions from all states - and estimate $V^{\\pi_{n}}$ based on this policy. It only changes policy once values converged.\n",
    "\n",
    "\n",
    "Below are a few helpers that you may or may not use in your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_probs = {\n",
    "    's0': {\n",
    "        'a0': {'s0': 0.5, 's2': 0.5},\n",
    "        'a1': {'s2': 1}\n",
    "    },\n",
    "    's1': {\n",
    "        'a0': {'s0': 0.7, 's1': 0.1, 's2': 0.2},\n",
    "        'a1': {'s1': 0.95, 's2': 0.05}\n",
    "    },\n",
    "    's2': {\n",
    "        'a0': {'s0': 0.4, 's1': 0.6},\n",
    "        'a1': {'s0': 0.3, 's1': 0.3, 's2': 0.4}\n",
    "    }\n",
    "}\n",
    "rewards = {\n",
    "    's1': {'a0': {'s0': +5}},\n",
    "    's2': {'a1': {'s0': -1}}\n",
    "}\n",
    "\n",
    "from mdp import MDP\n",
    "mdp = MDP(transition_probs, rewards, initial_state='s0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function called `compute_vpi` that computes the state-value function $V^{\\pi}$ for an arbitrary policy $\\pi$.\n",
    "\n",
    "Unlike VI, this time you must find the exact solution, not just a single iteration.\n",
    "\n",
    "Recall that $V^{\\pi}$ satisfies the following linear equation:\n",
    "$$V^{\\pi}(s) = \\sum_{s'} P(s,\\pi(s),s')[ R(s,\\pi(s),s') + \\gamma V^{\\pi}(s')]$$\n",
    "\n",
    "You'll have to solve a linear system in your code. (Find an exact solution, e.g., with `np.linalg.solve`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vpi(mdp, policy, gamma):\n",
    "    \"\"\"\n",
    "    Computes V^pi(s) FOR ALL STATES under given policy.\n",
    "    :param policy: a dict of currently chosen actions {s : a}\n",
    "    :returns: a dict {state : V^pi(state) for all states}\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return < YOUR CODE >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_policy = {s: np.random.choice(\n",
    "    mdp.get_possible_actions(s)) for s in mdp.get_all_states()}\n",
    "new_vpi = compute_vpi(mdp, test_policy, gamma)\n",
    "\n",
    "print(new_vpi)\n",
    "\n",
    "assert type(\n",
    "    new_vpi) is dict, \"compute_vpi must return a dict {state : V^pi(state) for all states}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've got new state values, it's time to update our policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_new_policy(mdp, vpi, gamma):\n",
    "    \"\"\"\n",
    "    Computes new policy as argmax of state values\n",
    "    :param vpi: a dict {state : V^pi(state) for all states}\n",
    "    :returns: a dict {state : optimal action for all states}\n",
    "    \"\"\"\n",
    "    <YOUR CODE >\n",
    "    return < YOUR CODE >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_policy = compute_new_policy(mdp, new_vpi, gamma)\n",
    "\n",
    "print(new_policy)\n",
    "\n",
    "assert type(\n",
    "    new_policy) is dict, \"compute_new_policy must return a dict {state : optimal action for all states}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Main loop__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_iteration(mdp, policy=None, gamma=0.9, num_iter=1000, min_difference=1e-5):\n",
    "    \"\"\" \n",
    "    Run the policy iteration loop for num_iter iterations or till difference between V(s) is below min_difference.\n",
    "    If policy is not given, initialize it at random.\n",
    "    \"\"\"\n",
    "    < A WHOLE LOT OF YOUR CODE >\n",
    "\n",
    "    return state_values, policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your PI Results__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "< Compare PI and VI on the MDP from bonus 1, then on small & large FrozenLake >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy iteration convergnece (3 pts)\n",
    "\n",
    "**Note:** Assume that $\\mathcal{S}, \\mathcal{A}$ are finite.\n",
    "\n",
    "We can define another Bellman operator:\n",
    "\n",
    "$$(T_{\\pi}V)(s) = \\mathbb{E}_{r, s'|s, a = \\pi(s)}\\left[r + \\gamma V(s')\\right]$$\n",
    "\n",
    "And rewrite policy iteration algorithm in operator form:\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Initialize $\\pi_0$\n",
    "\n",
    "**for** $k = 0,1,2,...$ **do**\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; Solve $V_k = T_{\\pi_k}V_k$   \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; Select $\\pi_{k+1}$ s.t. $T_{\\pi_{k+1}}V_k = TV_k$ \n",
    "\n",
    "**end for**\n",
    "\n",
    "---\n",
    "\n",
    "To prove convergence of the algorithm we need to prove two properties: contraction an monotonicity.\n",
    "\n",
    "#### Monotonicity (0.5 pts)\n",
    "\n",
    "For all $V, U$ if $V(s) \\le U(s)$   $\\forall s \\in \\mathcal{S}$ then $(T_\\pi V)(s) \\le (T_\\pi U)(s)$   $\\forall s \\in  \\mathcal{S}$\n",
    "\n",
    "*<-- Your proof here -->*\n",
    "\n",
    "#### Contraction (1 pts)\n",
    "\n",
    "$$\n",
    "||T_\\pi V - T_\\pi U||_{\\infty} \\le \\gamma ||V - U||_{\\infty}\n",
    "$$\n",
    "\n",
    "For all $V, U$\n",
    "\n",
    "*<-- Your proof here -->*\n",
    "\n",
    "#### Convergence (1.5 pts)\n",
    "\n",
    "Prove that there exists iteration $k_0$ such that $\\pi_k = \\pi^*$ for all $k \\ge k_0$\n",
    "\n",
    "*<-- Your proof here -->*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
